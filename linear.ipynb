{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear:\n",
    "    def __init__(\n",
    "        self, \n",
    "        in_features: int, \n",
    "        out_features: int, \n",
    "        bias: bool = True\n",
    "    ) -> None:\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        \n",
    "        self.weights = np.zeros((self.in_features, self.out_features))\n",
    "        if bias:\n",
    "            self.bias = np.zeros(self.out_features)    \n",
    "        else:\n",
    "            self.bias = None\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self, how: str='normal') -> None:\n",
    "        if how == 'normal':\n",
    "            self.weights = np.random.normal(0.0, 0.01, size = (self.out_features, self.in_features))\n",
    "            if self.bias is not None:\n",
    "                self.bias = np.random.normal(0, 0.01, size = (self.out_features))\n",
    "    \n",
    "    def __call__(self, inputs: np.ndarray) -> np.ndarray:\n",
    "        assert inputs.shape[0] == self.weights.shape[1]\n",
    "        return np.dot(self.weights, inputs) + self.bias        \n",
    "        \n",
    "    def backward(self, gradient: np.ndarray) -> np.ndarray:\n",
    "        self.weights_grad = np.dot(self.input.T, gradient)\n",
    "        self.bias_grad = np.sum(gradient, axis=0)\n",
    "        return gradient @ self.weights.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear1 = Linear(2, 3, bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = np.array([0.5, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = np.array([0.5, 0.3])\n",
    "output = linear1(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relu():\n",
    "    def __call__(self, x: np.ndarray) -> np.ndarray:\n",
    "        self.output = np.maximum(0, x)   \n",
    "        return self.output\n",
    "\n",
    "    def backward(self, grad):\n",
    "        return grad * np.clip(self.output, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSE:\n",
    "    def __call__(self, predict_values: np.ndarray, true_values: np.ndarray) -> float:\n",
    "        assert predict_values.shape == true_values.shape\n",
    "        self.error = predict_values - true_values\n",
    "        return np.mean(self.error ** 2)\n",
    "    \n",
    "    def backward(self):\n",
    "        return 2 * (1 / self.error.shape[-1]) * self.error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "class Softmax:\n",
    "    def __call__(self, inputs: np.ndarray) -> np.ndarray:\n",
    "        exps = exps - np.max(exps)\n",
    "        sm_logits = np.exp(exps) / np.sum(np.exp(exps))\n",
    "        return sm_logits\n",
    "\n",
    "    def backward(self, gradient: np.ndarray) -> np.ndarray:\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer:\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "    \n",
    "    def step(self, model: Any, loss: Any) -> None:\n",
    "        pass\n",
    "\n",
    "\n",
    "class SGD(Optimizer):\n",
    "    def __init__(self, learning_rate: float) -> None:\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "    def step(self, model: Any, loss: Any) -> None:\n",
    "        error_gradient = loss.backward()\n",
    "        for layer in model.layers:\n",
    "            layer.backward(error_gradient)\n",
    "            layer.weights -= self.learning_rate * layer.weights_grad\n",
    "            if layer.bias is not None:\n",
    "                layer.bias -= self.learning_rate * layer.bias_grad\n",
    "                \n",
    "class Adam(Optimizer):\n",
    "    def __init__(self, params, lr=0.001, betas=(0.9, 0.999), eps=1e-8):\n",
    "        self.params = params\n",
    "        self.lr = lr\n",
    "        self.betas = betas\n",
    "        self.eps = eps\n",
    "        self.t = 0\n",
    "        self.v = {param: np.zeros(param) for param in self.params}\n",
    "        self.m = {param: np.zeros(param) for param in self.params}\n",
    "\n",
    "    def step(self):\n",
    "        self.t += 1\n",
    "        for param in self.params:\n",
    "            grad = param.grad.data\n",
    "            self.v[param] = self.betas[0] * self.v[param] + (1 - self.betas[0]) * grad\n",
    "            self.m[param] = self.betas[1] * self.m[param] + (1 - self.betas[1]) * (grad * grad)\n",
    "            v_corrected = self.v[param] / (1 - self.betas[0]**self.t)\n",
    "            m_corrected = self.m[param] / (1 - self.betas[1]**self.t)\n",
    "            param.data -= self.lr * v_corrected / (m_corrected.sqrt() + self.eps)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
